{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5TGh72R7G4V",
        "outputId": "ca145ca0-6e19-4b77-e159-2e18ba7923ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023/12/18 22:37:12 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "mlflow.autolog()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIsSz2m9EXGW",
        "outputId": "735d2c29-a307-494c-c1d6-2c9a52145e86"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>Tags</th>\n",
              "      <th>Score</th>\n",
              "      <th>ViewCount</th>\n",
              "      <th>AnswerCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20485075</td>\n",
              "      <td>How do I define multiple conditions on a join ...</td>\n",
              "      <td>&lt;p&gt;Ok, lets say I have order and items tables....</td>\n",
              "      <td>&lt;java&gt;&lt;jpa&gt;&lt;playframework&gt;&lt;playframework-2.0&gt;&lt;...</td>\n",
              "      <td>1</td>\n",
              "      <td>1984</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20485079</td>\n",
              "      <td>What is the equivalent of a C# gridview in jav...</td>\n",
              "      <td>&lt;p&gt;I am trying to learn java, I am working on ...</td>\n",
              "      <td>&lt;c#&gt;&lt;java&gt;&lt;asp.net&gt;&lt;swing&gt;&lt;gridview&gt;</td>\n",
              "      <td>2</td>\n",
              "      <td>12333</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20485143</td>\n",
              "      <td>Listview cursor adapter, always get first item...</td>\n",
              "      <td>&lt;p&gt;I have this piece of code for listview usin...</td>\n",
              "      <td>&lt;android&gt;&lt;listview&gt;&lt;android-listview&gt;&lt;simplecu...</td>\n",
              "      <td>1</td>\n",
              "      <td>1075</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20485144</td>\n",
              "      <td>OpenSSL RSA-2048 unencrypted block is longer t...</td>\n",
              "      <td>&lt;p&gt;I am using the OpenSSL library in order to ...</td>\n",
              "      <td>&lt;c&gt;&lt;encryption&gt;&lt;cryptography&gt;&lt;openssl&gt;&lt;rsa&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>527</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20485176</td>\n",
              "      <td>Returning char into main method</td>\n",
              "      <td>&lt;p&gt;The goal of my program is kind of like whee...</td>\n",
              "      <td>&lt;java&gt;&lt;eclipse&gt;&lt;string&gt;&lt;methods&gt;&lt;char&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>1278</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>22814994</td>\n",
              "      <td>StructureMap use specific instance of type per...</td>\n",
              "      <td>&lt;p&gt;Is there a way, using StructureMap (the Dep...</td>\n",
              "      <td>&lt;c#&gt;&lt;asp.net&gt;&lt;dependency-injection&gt;&lt;inversion-...</td>\n",
              "      <td>0</td>\n",
              "      <td>369</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>22815009</td>\n",
              "      <td>Add a reference column migration in Rails 4</td>\n",
              "      <td>&lt;p&gt;A user has many uploads. I want to add a co...</td>\n",
              "      <td>&lt;ruby-on-rails&gt;&lt;ruby-on-rails-4&gt;&lt;foreign-keys&gt;...</td>\n",
              "      <td>368</td>\n",
              "      <td>397557</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>22815010</td>\n",
              "      <td>Hibernate mapping with group by clause?</td>\n",
              "      <td>&lt;p&gt;I have &lt;code&gt;@OneToMany&lt;/code&gt; mapping in a...</td>\n",
              "      <td>&lt;java&gt;&lt;sql&gt;&lt;hibernate&gt;&lt;group-by&gt;&lt;hibernate-map...</td>\n",
              "      <td>0</td>\n",
              "      <td>1755</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>22815022</td>\n",
              "      <td>java.lang.NoClassDefFoundError: android.suppor...</td>\n",
              "      <td>&lt;p&gt;I have a class that extends &lt;code&gt;android.s...</td>\n",
              "      <td>&lt;java&gt;&lt;android&gt;&lt;eclipse&gt;&lt;android-fragments&gt;&lt;an...</td>\n",
              "      <td>0</td>\n",
              "      <td>1441</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>58709</td>\n",
              "      <td>How to log in T-SQL</td>\n",
              "      <td>&lt;p&gt;I'm using ADO.NET to access SQL Server 2005...</td>\n",
              "      <td>&lt;sql-server&gt;&lt;t-sql&gt;&lt;logging&gt;&lt;ado.net&gt;&lt;sql&gt;</td>\n",
              "      <td>14</td>\n",
              "      <td>25293</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Id                                              Title  \\\n",
              "0      20485075  How do I define multiple conditions on a join ...   \n",
              "1      20485079  What is the equivalent of a C# gridview in jav...   \n",
              "2      20485143  Listview cursor adapter, always get first item...   \n",
              "3      20485144  OpenSSL RSA-2048 unencrypted block is longer t...   \n",
              "4      20485176                    Returning char into main method   \n",
              "...         ...                                                ...   \n",
              "49995  22814994  StructureMap use specific instance of type per...   \n",
              "49996  22815009        Add a reference column migration in Rails 4   \n",
              "49997  22815010            Hibernate mapping with group by clause?   \n",
              "49998  22815022  java.lang.NoClassDefFoundError: android.suppor...   \n",
              "49999     58709                                How to log in T-SQL   \n",
              "\n",
              "                                                    Body  \\\n",
              "0      <p>Ok, lets say I have order and items tables....   \n",
              "1      <p>I am trying to learn java, I am working on ...   \n",
              "2      <p>I have this piece of code for listview usin...   \n",
              "3      <p>I am using the OpenSSL library in order to ...   \n",
              "4      <p>The goal of my program is kind of like whee...   \n",
              "...                                                  ...   \n",
              "49995  <p>Is there a way, using StructureMap (the Dep...   \n",
              "49996  <p>A user has many uploads. I want to add a co...   \n",
              "49997  <p>I have <code>@OneToMany</code> mapping in a...   \n",
              "49998  <p>I have a class that extends <code>android.s...   \n",
              "49999  <p>I'm using ADO.NET to access SQL Server 2005...   \n",
              "\n",
              "                                                    Tags  Score  ViewCount  \\\n",
              "0      <java><jpa><playframework><playframework-2.0><...      1       1984   \n",
              "1                   <c#><java><asp.net><swing><gridview>      2      12333   \n",
              "2      <android><listview><android-listview><simplecu...      1       1075   \n",
              "3            <c><encryption><cryptography><openssl><rsa>      0        527   \n",
              "4                 <java><eclipse><string><methods><char>      0       1278   \n",
              "...                                                  ...    ...        ...   \n",
              "49995  <c#><asp.net><dependency-injection><inversion-...      0        369   \n",
              "49996  <ruby-on-rails><ruby-on-rails-4><foreign-keys>...    368     397557   \n",
              "49997  <java><sql><hibernate><group-by><hibernate-map...      0       1755   \n",
              "49998  <java><android><eclipse><android-fragments><an...      0       1441   \n",
              "49999         <sql-server><t-sql><logging><ado.net><sql>     14      25293   \n",
              "\n",
              "       AnswerCount  \n",
              "0                2  \n",
              "1                1  \n",
              "2                2  \n",
              "3                1  \n",
              "4                3  \n",
              "...            ...  \n",
              "49995            2  \n",
              "49996            8  \n",
              "49997            1  \n",
              "49998            1  \n",
              "49999           11  \n",
              "\n",
              "[50000 rows x 7 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# @title Importation données\n",
        "import pandas as pd\n",
        "ct = 'QueryResults (1).csv'\n",
        "df = pd.read_csv(ct)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huR4tiF_EXEQ",
        "outputId": "a49dc6a3-f6eb-48bd-a19b-f1f660052d36"
      },
      "outputs": [],
      "source": [
        "# @title Filtre des tags\n",
        "\n",
        "df['Tags'] = df['Tags'].str.replace('><', ',').str.replace('<', '').str.replace('>', '')\n",
        "\n",
        "from collections import Counter\n",
        "# Fréquence des mots dans 'Tags'\n",
        "all_tags = df['Tags'].str.split(',').explode().tolist()\n",
        "tag_counts = Counter(all_tags)\n",
        "\n",
        "# Trouver les 50 mots les plus fréquents\n",
        "top_50_tags = [tag for tag, _ in tag_counts.most_common(50)]\n",
        "\n",
        "# Filtrer les listes de mots pour ne contenir que les 50 mots les plus fréquents\n",
        "def filter_tags(tags):\n",
        "    return [tag for tag in tags if tag in top_50_tags]\n",
        "\n",
        "df['Tags'] = df['Tags'].str.split(',').apply(filter_tags)\n",
        "\n",
        "# Filtrer les lignes où 'Tags' est vide après le filtrage\n",
        "df = df[df['Tags'].apply(len) > 0]\n",
        "\n",
        "df['nb_tags'] = df['Tags'].apply(lambda x: len(x))\n",
        "df = df[df['nb_tags']==3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYlaWV3dEXB6",
        "outputId": "04bf8734-0e1f-4b03-f453-f59715ab6286"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading Users: <urlopen error [SSL:\n",
            "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
            "[nltk_data]     self signed certificate in certificate chain\n",
            "[nltk_data]     (_ssl.c:997)>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "custom_stopwords existe\n",
            "stop_w good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n",
            "stp\n",
            "entrée tokenizer\n",
            "sentence cleaned\n",
            "tokenizer good\n",
            "word_tokens good\n",
            "fait\n",
            "list_words type =  <class 'list'>\n",
            "filtered_w good\n",
            "stop_word_filter_fct good\n",
            "sw existe\n",
            "un\n",
            "lower good\n",
            "lower  existe\n",
            "transform_bow_fct good\n"
          ]
        }
      ],
      "source": [
        "# @title Nettoyage du texte\n",
        "import pickle\n",
        "import nltk\n",
        "nltk.download('Users')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "custom_punkt_path = '/Users/orphila_adjovi/PJT5_Open_classrooms_MLE/corpora/punkt'\n",
        "punkt_path = nltk.data.find(f'{custom_punkt_path}/english.pickle')\n",
        "with open(punkt_path, 'rb') as file:\n",
        "    punkt_model = pickle.load(file)\n",
        "#nltk.data.path.append(custom_punkt_path)\n",
        "\n",
        "with open('/Users/orphila_adjovi/PJT5_Open_classrooms_MLE/corpora/stopwords/english', 'r') as file:\n",
        "    custom_stopwords = file.read().splitlines()\n",
        "    print('custom_stopwords existe')\n",
        "    \n",
        "# Nettoyage\n",
        "def tokenizer_fct(sentence):\n",
        "    print('entrée tokenizer')\n",
        "    \"\"\"Division de mots en texte + suppression de certains caractères\"\"\"\n",
        "    sentence_clean = sentence.replace('-', ' ').replace('+', ' ').replace('/', ' ').replace('#', ' ')\n",
        "    print('sentence cleaned')\n",
        "    #word_tokens = word_tokenize(sentence_clean, language='english', path_to_punkt=punkt_path)\n",
        "    word_tokens = punkt_model.tokenize(sentence_clean)\n",
        "    print('tokenizer good')\n",
        "    return word_tokens\n",
        "\n",
        "\n",
        "stop_w = custom_stopwords + ['[', ']', ',', '.', ':', '?', '(', ')','<','>','~']\n",
        "print('stop_w good')\n",
        "def stop_word_filter_fct(list_words):\n",
        "    print('fait')\n",
        "    \"\"\"Suppression de mots sans information+ ponctuations\"\"\"\n",
        "    print('list_words type = ',type(list_words))\n",
        "    filtered_w = [w for w in list_words if not w in stop_w]\n",
        "    print('filtered_w good')\n",
        "    filtered_w2 = [w for w in filtered_w if len(w) > 2]\n",
        "    print('stop_word_filter_fct good')\n",
        "    return filtered_w2\n",
        "\n",
        "def lower_start_fct(list_words):\n",
        "    print('un')\n",
        "    \"\"\"Conversion en lettres minuscules et suppression de préfixes indésirables\"\"\"\n",
        "    lw = [w.lower() for w in list_words if (not w.startswith(\"@\")) and (not w.startswith(\"#\")) and (not w.startswith(\"http\"))]\n",
        "    print('lower good')\n",
        "    return lw\n",
        "\n",
        "def lemma_fct(list_words):\n",
        "    print('truc')\n",
        "    \"\"\"lemmatisation\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lem_w = [lemmatizer.lemmatize(w) for w in list_words]\n",
        "    print('lemma good')\n",
        "    return lem_w\n",
        "\n",
        "def transform_bow_fct(desc_text):\n",
        "    print('stp')\n",
        "    \"\"\"fonction de transformation\"\"\"\n",
        "    word_tokens = tokenizer_fct(desc_text)\n",
        "    print('word_tokens good')\n",
        "    sw = stop_word_filter_fct(word_tokens)\n",
        "    print('sw existe')\n",
        "    lw = lower_start_fct(sw)\n",
        "    print('lower  existe')\n",
        "    transf_desc_text = ' '.join(lw)\n",
        "    print('transform_bow_fct good')\n",
        "    return transf_desc_text\n",
        "\n",
        "# Prétraitement\n",
        "df['Cleaned_Body'] = df['Body'].apply(transform_bow_fct)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "to1F1RYLEW_i"
      },
      "outputs": [],
      "source": [
        "# @title Encoding TF - IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
        "tfidf_array = tfidf_vectorizer.fit_transform(df['Cleaned_Body']).toarray()\n",
        "\n",
        "# Liste des termes correspondant aux colonnes de la matrice\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "# Scores de chaque mot\n",
        "tfidf_df = pd.DataFrame(tfidf_array, columns=feature_names)\n",
        "\n",
        "# Concaténez les DataFrames sans utiliser de sample\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df2 = pd.concat([df, tfidf_df], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modèle supervisé"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsmfcu3JEW9O",
        "outputId": "39f464f8-bfb6-4ddc-9bd0-c50b4e7438b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023/12/18 22:37:16 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/orphila_adjovi/PJT5_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/mlflow/data/digest_utils.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\"\n",
            "/Users/orphila_adjovi/PJT5_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/orphila_adjovi/PJT5_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
            "  warnings.warn(\n",
            "2023/12/18 22:37:26 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/orphila_adjovi/PJT5_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
            "Registered model 'supervised_tfidf_vec' already exists. Creating a new version of this model...\n",
            "Created version '4' of model 'supervised_tfidf_vec'.\n",
            "2023/12/18 22:37:28 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
            "Registered model 'supervised' already exists. Creating a new version of this model...\n",
            "Created version '14' of model 'supervised'.\n",
            "2023/12/18 22:37:30 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/orphila_adjovi/PJT5_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/mlflow/data/digest_utils.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La précision du modèle supervisé avec  tf_idf  est de  19.0  % \n"
          ]
        }
      ],
      "source": [
        "import random as rd\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "rd.seed(0)\n",
        "\n",
        "def modelisation(enc,name):\n",
        "    # Convertir les étiquettes ('Tags') en un format binaire\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    #binary_labels = mlb.fit_transform(df['Tags']).tolist()\n",
        "    # Diviser les données pour l'entraînement et le test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(enc, df['Tags'], test_size=0.2, random_state=42)\n",
        "    y_train = [y[rd.randint(0, 2)] for y in y_train]\n",
        "    y_test = [y[rd.randint(0, 2)] for y in y_test]\n",
        "\n",
        "    # Initialisation et entrainement du modèle\n",
        "    with mlflow.start_run(run_name= 'supervised_'+name+' last') as run:\n",
        "        naive_bayes = MultinomialNB()\n",
        "        naive_bayes.fit(X_train, y_train)\n",
        "        mlflow.sklearn.log_model(\n",
        "            sk_model=naive_bayes,\n",
        "            artifact_path=\"model\",\n",
        "            registered_model_name=\"supervised_tfidf_vec\",\n",
        "        )\n",
        "        mlflow.sklearn.log_model(\n",
        "            sk_model=tfidf_vectorizer, \n",
        "            artifact_path=\"tfidf_vectorizer\", \n",
        "            registered_model_name=\"supervised\")\n",
        "\n",
        "\n",
        "    # Prédictions\n",
        "    predicted_tags = naive_bayes.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, predicted_tags)\n",
        "\n",
        "    print(\"La précision du modèle supervisé avec \",name,\" est de \",round(accuracy,2)*100,\" % \")\n",
        "\n",
        "modelisation(tfidf_df,'tf_idf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluation du drift avec evidently"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\"/>\n",
              "<style>\n",
              ".reset-this-parent {\n",
              "  all: initial;\n",
              "}\n",
              ".reset-this-parent h5 {\n",
              "  all: initial;\n",
              "  font: initial;\n",
              "}\n",
              "\n",
              "svg {\n",
              "  height: intrinsic !important;\n",
              "}\n",
              "</style>\n",
              "<script>\n",
              "    var evidently_dashboard_51152a7f0a884cc69b9172262e8c9667 = {\"name\": \"Report\", \"widgets\": [{\"type\": \"counter\", \"title\": \"\", \"size\": 2, \"id\": \"88bff41f-d1c4-4551-b491-60344fc65eb1\", \"details\": \"\", \"alertsPosition\": null, \"alertStats\": null, \"params\": {\"counters\": [{\"value\": \"Dataset Drift\", \"label\": \"Dataset Drift is detected. Dataset drift detection threshold is 0.5\"}]}, \"insights\": [], \"alerts\": [], \"tabs\": [], \"widgets\": [], \"pageSize\": 5}, {\"type\": \"counter\", \"title\": \"\", \"size\": 2, \"id\": \"b544a7bc-d3c1-4e89-89ef-98dbc5c11477\", \"details\": \"\", \"alertsPosition\": null, \"alertStats\": null, \"params\": {\"counters\": [{\"value\": \"1\", \"label\": \"Columns\"}, {\"value\": \"1\", \"label\": \"Drifted Columns\"}, {\"value\": \"1.0\", \"label\": \"Share of Drifted Columns\"}]}, \"insights\": [], \"alerts\": [], \"tabs\": [], \"widgets\": [], \"pageSize\": 5}, {\"type\": \"counter\", \"title\": \"\", \"size\": 2, \"id\": \"fb81300e-4f8c-4d58-999e-d153a1e55799\", \"details\": \"\", \"alertsPosition\": null, \"alertStats\": null, \"params\": {\"counters\": [{\"value\": \"\", \"label\": \"Data Drift Summary\"}]}, \"insights\": [], \"alerts\": [], \"tabs\": [], \"widgets\": [], \"pageSize\": 5}, {\"type\": \"big_table\", \"title\": \"Drift is detected for 100.0% of columns (1 out of 1).\", \"size\": 2, \"id\": \"b757657f-b91f-45d9-9dc5-027133733800\", \"details\": \"\", \"alertsPosition\": \"row\", \"alertStats\": null, \"params\": {\"rowsPerPage\": 1, \"columns\": [{\"title\": \"Column\", \"field\": \"column_name\"}, {\"title\": \"Type\", \"field\": \"column_type\"}, {\"title\": \"Reference Distribution\", \"field\": \"reference_distribution\", \"type\": \"histogram\", \"options\": {\"xField\": \"x\", \"yField\": \"y\", \"color\": \"#ed0400\"}}, {\"title\": \"Current Distribution\", \"field\": \"current_distribution\", \"type\": \"histogram\", \"options\": {\"xField\": \"x\", \"yField\": \"y\", \"color\": \"#ed0400\"}}, {\"title\": \"Data Drift\", \"field\": \"data_drift\"}, {\"title\": \"Stat Test\", \"field\": \"stattest_name\"}, {\"title\": \"Drift Score\", \"field\": \"drift_score\"}], \"data\": [{\"details\": {\"parts\": [{\"title\": \"DATA DISTRIBUTION\", \"id\": \"1cc48681-3070-4d39-8c97-991871e2498c\", \"type\": \"widget\"}]}, \"column_name\": \"Target\", \"column_type\": \"cat\", \"stattest_name\": \"Jensen-Shannon distance\", \"reference_distribution\": {\"x\": [\".net\", \"ajax\", \"android\", \"angular\", \"angularjs\", \"arrays\", \"asp.net\", \"asp.net-mvc\", \"c\", \"c#\", \"c++\", \"css\", \"database\", \"django\", \"forms\", \"html\", \"image\", \"ios\", \"iphone\", \"java\", \"javascript\", \"jquery\", \"json\", \"linux\", \"macos\", \"multithreading\", \"mysql\", \"node.js\", \"objective-c\", \"pandas\", \"performance\", \"php\", \"python\", \"python-3.x\", \"reactjs\", \"regex\", \"ruby\", \"ruby-on-rails\", \"spring\", \"spring-boot\", \"sql\", \"sql-server\", \"string\", \"swift\", \"visual-studio\", \"windows\", \"wordpress\", \"wpf\", \"xcode\", \"xml\"], \"y\": [41, 29, 25, 8, 12, 25, 29, 12, 14, 72, 18, 39, 20, 8, 13, 89, 8, 51, 26, 50, 121, 66, 21, 4, 6, 12, 37, 21, 38, 8, 14, 50, 40, 21, 9, 5, 7, 15, 17, 21, 29, 6, 23, 14, 9, 13, 10, 11, 17, 15]}, \"current_distribution\": {\"x\": [\".net\", \"ajax\", \"android\", \"angular\", \"angularjs\", \"arrays\", \"asp.net\", \"asp.net-mvc\", \"c\", \"c#\", \"c++\", \"css\", \"database\", \"django\", \"forms\", \"html\", \"image\", \"ios\", \"iphone\", \"java\", \"javascript\", \"jquery\", \"json\", \"linux\", \"macos\", \"multithreading\", \"mysql\", \"node.js\", \"objective-c\", \"pandas\", \"performance\", \"php\", \"python\", \"python-3.x\", \"reactjs\", \"regex\", \"ruby\", \"ruby-on-rails\", \"spring\", \"spring-boot\", \"sql\", \"sql-server\", \"string\", \"swift\", \"visual-studio\", \"windows\", \"wordpress\", \"wpf\", \"xcode\", \"xml\"], \"y\": [3, 0, 1, 0, 0, 1, 2, 1, 0, 6, 0, 1, 0, 0, 0, 6, 0, 4, 2, 1, 3, 6, 1, 2, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 1, 3, 2, 3, 2, 0, 0, 1, 1, 0]}, \"data_drift\": \"Detected\", \"drift_score\": 0.384368}]}, \"insights\": [], \"alerts\": [], \"tabs\": [], \"widgets\": [], \"pageSize\": 5}]};\n",
              "    var additional_graphs_evidently_dashboard_51152a7f0a884cc69b9172262e8c9667 = {\"1cc48681-3070-4d39-8c97-991871e2498c\": {\"type\": \"big_graph\", \"title\": \"\", \"size\": 2, \"id\": \"1cc48681-3070-4d39-8c97-991871e2498c\", \"details\": \"\", \"alertsPosition\": null, \"alertStats\": null, \"params\": {\"data\": [{\"marker\": {\"color\": \"#ed0400\"}, \"name\": \"current\", \"visible\": true, \"x\": [\"jquery\", \"c#\", \"html\", \"ios\", \".net\", \"sql-server\", \"javascript\", \"swift\", \"string\", \"regex\", \"asp.net\", \"iphone\", \"visual-studio\", \"linux\", \"xcode\", \"python\", \"mysql\", \"sql\", \"java\", \"multithreading\", \"arrays\", \"json\", \"css\", \"android\", \"asp.net-mvc\", \"php\", \"wpf\", \"objective-c\"], \"y\": [6, 6, 6, 4, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"type\": \"bar\", \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"#ed0400\"}, \"name\": \"current\", \"visible\": false, \"x\": [\"jquery\", \"c#\", \"html\", \"ios\", \".net\", \"sql-server\", \"javascript\", \"swift\", \"string\", \"regex\", \"asp.net\", \"iphone\", \"visual-studio\", \"linux\", \"xcode\", \"python\", \"mysql\", \"sql\", \"java\", \"multithreading\", \"arrays\", \"json\", \"css\", \"android\", \"asp.net-mvc\", \"php\", \"wpf\", \"objective-c\"], \"y\": [10.0, 10.0, 10.0, 6.666666666666667, 5.0, 5.0, 5.0, 5.0, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667], \"type\": \"bar\", \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"#4d4d4d\"}, \"name\": \"reference\", \"visible\": true, \"x\": [\"javascript\", \"html\", \"c#\", \"jquery\", \"ios\", \"php\", \"java\", \".net\", \"python\", \"css\", \"objective-c\", \"mysql\", \"asp.net\", \"ajax\", \"sql\", \"iphone\", \"arrays\", \"android\", \"string\", \"spring-boot\", \"python-3.x\", \"json\", \"node.js\", \"database\", \"c++\", \"spring\", \"xcode\", \"xml\", \"ruby-on-rails\", \"swift\", \"performance\", \"c\", \"windows\", \"forms\", \"asp.net-mvc\", \"angularjs\", \"multithreading\", \"wpf\", \"wordpress\", \"visual-studio\", \"reactjs\", \"django\", \"angular\", \"image\", \"pandas\", \"ruby\", \"macos\", \"sql-server\", \"regex\", \"linux\"], \"y\": [121, 89, 72, 66, 51, 50, 50, 41, 40, 39, 38, 37, 29, 29, 29, 26, 25, 25, 23, 21, 21, 21, 21, 20, 18, 17, 17, 15, 15, 14, 14, 14, 13, 13, 12, 12, 12, 11, 10, 9, 9, 8, 8, 8, 8, 7, 6, 6, 5, 4], \"type\": \"bar\", \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"#4d4d4d\"}, \"name\": \"reference\", \"visible\": false, \"x\": [\"javascript\", \"html\", \"c#\", \"jquery\", \"ios\", \"php\", \"java\", \".net\", \"python\", \"css\", \"objective-c\", \"mysql\", \"asp.net\", \"ajax\", \"sql\", \"iphone\", \"arrays\", \"android\", \"string\", \"spring-boot\", \"python-3.x\", \"json\", \"node.js\", \"database\", \"c++\", \"spring\", \"xcode\", \"xml\", \"ruby-on-rails\", \"swift\", \"performance\", \"c\", \"windows\", \"forms\", \"asp.net-mvc\", \"angularjs\", \"multithreading\", \"wpf\", \"wordpress\", \"visual-studio\", \"reactjs\", \"django\", \"angular\", \"image\", \"pandas\", \"ruby\", \"macos\", \"sql-server\", \"regex\", \"linux\"], \"y\": [9.535066981875492, 7.0133963750985036, 5.673758865248227, 5.200945626477541, 4.0189125295508275, 3.940110323089047, 3.940110323089047, 3.230890464933018, 3.152088258471237, 3.0732860520094563, 2.9944838455476757, 2.9156816390858946, 2.2852639873916467, 2.2852639873916467, 2.2852639873916467, 2.048857368006304, 1.9700551615445234, 1.9700551615445234, 1.8124507486209613, 1.6548463356973995, 1.6548463356973995, 1.6548463356973995, 1.6548463356973995, 1.5760441292356184, 1.4184397163120568, 1.3396375098502757, 1.3396375098502757, 1.1820330969267139, 1.1820330969267139, 1.103230890464933, 1.103230890464933, 1.103230890464933, 1.024428684003152, 1.024428684003152, 0.9456264775413712, 0.9456264775413712, 0.9456264775413712, 0.8668242710795903, 0.7880220646178092, 0.7092198581560284, 0.7092198581560284, 0.6304176516942475, 0.6304176516942475, 0.6304176516942475, 0.6304176516942475, 0.5516154452324665, 0.4728132387706856, 0.4728132387706856, 0.3940110323089046, 0.31520882584712373], \"type\": \"bar\", \"xaxis\": \"x\", \"yaxis\": \"y\"}], \"layout\": {\"template\": {\"data\": {\"histogram2dcontour\": [{\"type\": \"histogram2dcontour\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}], \"choropleth\": [{\"type\": \"choropleth\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}], \"histogram2d\": [{\"type\": \"histogram2d\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}], \"heatmap\": [{\"type\": \"heatmap\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}], \"heatmapgl\": [{\"type\": \"heatmapgl\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}], \"contourcarpet\": [{\"type\": \"contourcarpet\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}], \"contour\": [{\"type\": \"contour\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}], \"surface\": [{\"type\": \"surface\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}], \"mesh3d\": [{\"type\": \"mesh3d\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}], \"scatter\": [{\"fillpattern\": {\"fillmode\": \"overlay\", \"size\": 10, \"solidity\": 0.2}, \"type\": \"scatter\"}], \"parcoords\": [{\"type\": \"parcoords\", \"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"scatterpolargl\": [{\"type\": \"scatterpolargl\", \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}, \"pattern\": {\"fillmode\": \"overlay\", \"size\": 10, \"solidity\": 0.2}}, \"type\": \"bar\"}], \"scattergeo\": [{\"type\": \"scattergeo\", \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"scatterpolar\": [{\"type\": \"scatterpolar\", \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"histogram\": [{\"marker\": {\"pattern\": {\"fillmode\": \"overlay\", \"size\": 10, \"solidity\": 0.2}}, \"type\": \"histogram\"}], \"scattergl\": [{\"type\": \"scattergl\", \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"scatter3d\": [{\"type\": \"scatter3d\", \"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"scattermapbox\": [{\"type\": \"scattermapbox\", \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"scatterternary\": [{\"type\": \"scatterternary\", \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"scattercarpet\": [{\"type\": \"scattercarpet\", \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}, \"pattern\": {\"fillmode\": \"overlay\", \"size\": 10, \"solidity\": 0.2}}, \"type\": \"barpolar\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}]}, \"layout\": {\"autotypenumbers\": \"strict\", \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"hovermode\": \"closest\", \"hoverlabel\": {\"align\": \"left\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"bgcolor\": \"#E5ECF6\", \"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"ternary\": {\"bgcolor\": \"#E5ECF6\", \"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]]}, \"xaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"automargin\": true, \"zerolinewidth\": 2}, \"yaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"automargin\": true, \"zerolinewidth\": 2}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\", \"gridwidth\": 2}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\", \"gridwidth\": 2}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\", \"gridwidth\": 2}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"geo\": {\"bgcolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"subunitcolor\": \"white\", \"showland\": true, \"showlakes\": true, \"lakecolor\": \"white\"}, \"title\": {\"x\": 0.05}, \"mapbox\": {\"style\": \"light\"}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Count\"}}, \"updatemenus\": [{\"buttons\": [{\"args\": [{\"visible\": [true, false, true, false]}, {\"yaxis\": {\"title\": \"Count\"}}], \"label\": \"abs\", \"method\": \"update\"}, {\"args\": [{\"visible\": [false, true, false, true]}, {\"yaxis\": {\"title\": \"Percent\"}}], \"label\": \"perc\", \"method\": \"update\"}], \"direction\": \"right\", \"type\": \"buttons\", \"x\": 1.05, \"y\": 1.2, \"yanchor\": \"top\"}]}}, \"insights\": [], \"additionalGraphs\": [], \"alerts\": [], \"tabs\": [], \"widgets\": [], \"pageSize\": 5}};\n",
              "</script>\n",
              "<script>\n",
              "function domReady(fn) {\n",
              "  // If we're early to the party\n",
              "  document.addEventListener(\"DOMContentLoaded\", fn);\n",
              "  // If late; I mean on time.\n",
              "  if (document.readyState === \"interactive\" || document.readyState === \"complete\" ) {\n",
              "    fn();\n",
              "  }\n",
              "}\n",
              "\n",
              "domReady(function () {\n",
              "    requirejs([\"evidently\"], function(ev) {\n",
              "        drawDashboard(evidently_dashboard_51152a7f0a884cc69b9172262e8c9667,\n",
              "        new Map(Object.entries(additional_graphs_evidently_dashboard_51152a7f0a884cc69b9172262e8c9667)),\n",
              "        \"root_evidently_dashboard_51152a7f0a884cc69b9172262e8c9667\");\n",
              "    },\n",
              "    function(err) {\n",
              "        $(\"#root_evidently_dashboard_51152a7f0a884cc69b9172262e8c9667\").innerHTML = \"Failed to load\";\n",
              "    })\n",
              "});\n",
              "</script>\n",
              "<div class=\"reset-this-parent\" id=\"root_evidently_dashboard_51152a7f0a884cc69b9172262e8c9667\">Loading...</div>\n",
              "\n"
            ],
            "text/plain": [
              "<evidently.report.report.Report at 0x7ff39001dab0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from evidently.test_suite import TestSuite\n",
        "from evidently.test_preset import DataStabilityTestPreset\n",
        "\n",
        "from evidently.report import Report\n",
        "from evidently.metric_preset import DataDriftPreset\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_df, df['Tags'], test_size=0.2, random_state=42)\n",
        "y_train = [y[rd.randint(0, 2)] for y in y_train]\n",
        "y_test = [y[rd.randint(0, 2)] for y in y_test]\n",
        "\n",
        "df_y_train = pd.DataFrame(y_train, columns=['Target'])\n",
        "df_y_test = pd.DataFrame(y_test, columns=['Target'])\n",
        "\n",
        "data_stability= TestSuite(tests=[DataStabilityTestPreset(),])\n",
        "data_stability.run(current_data=df_y_train, reference_data=df_y_test, column_mapping=None)\n",
        "data_stability \n",
        "\n",
        "data_drift_report = Report(metrics=[DataDriftPreset(),])\n",
        "\n",
        "data_drift_report.run(current_data=df_y_train, reference_data=df_y_test, column_mapping=None)\n",
        "data_drift_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\"/>\n",
              "<style>\n",
              ".reset-this-parent {\n",
              "  all: initial;\n",
              "}\n",
              ".reset-this-parent h5 {\n",
              "  all: initial;\n",
              "  font: initial;\n",
              "}\n",
              "\n",
              "svg {\n",
              "  height: intrinsic !important;\n",
              "}\n",
              "</style>\n",
              "<script>\n",
              "    var evidently_dashboard_f659b36f1e764defbd52061ceca44590 = {\"name\": \"Test Suite\", \"widgets\": [{\"type\": \"counter\", \"title\": \"\", \"size\": 2, \"id\": \"c778bedb-1f14-4ea4-b6f2-c1f4d137f27f\", \"details\": \"\", \"alertsPosition\": null, \"alertStats\": null, \"params\": {\"counters\": [{\"value\": \"5\", \"label\": \"Tests\"}, {\"value\": \"4\", \"label\": \"Success\"}, {\"value\": \"0\", \"label\": \"Warning\"}, {\"value\": \"1\", \"label\": \"Fail\"}, {\"value\": \"0\", \"label\": \"Error\"}]}, \"insights\": [], \"alerts\": [], \"tabs\": [], \"widgets\": [], \"pageSize\": 5}, {\"type\": \"test_suite\", \"title\": \"\", \"size\": 2, \"id\": \"6c9b3c60-5978-4916-a106-a3d6548515a2\", \"details\": \"\", \"alertsPosition\": null, \"alertStats\": null, \"params\": {\"tests\": [{\"title\": \"Number of Rows\", \"description\": \"The number of rows is 5315. The test threshold is eq=1.33e+03 \\u00b1 133.\", \"state\": \"fail\", \"details\": {\"parts\": []}, \"groups\": {\"test_group\": \"data_integrity\", \"test_type\": \"Number of Rows\"}}, {\"title\": \"Number of Columns\", \"description\": \"The number of columns is 1. The test threshold is eq=1.\", \"state\": \"success\", \"details\": {\"parts\": [{\"id\": \"number_of_column\", \"title\": \"\", \"type\": \"widget\"}]}, \"groups\": {\"test_group\": \"data_integrity\", \"test_type\": \"Number of Columns\"}}, {\"title\": \"Column Types\", \"description\": \"The number of columns with a type mismatch is 0 out of 1.\", \"state\": \"success\", \"details\": {\"parts\": [{\"id\": \"cd1c0672-63b1-4dd8-bfb2-8b1da08f8ac3\", \"title\": \"\", \"type\": \"widget\"}]}, \"groups\": {\"test_group\": \"data_integrity\", \"test_type\": \"Column Types\"}}, {\"title\": \"The Share of Missing Values in a Column\", \"description\": \"The share of missing values in the column **Target** is 0. The test threshold is lte=0 \\u00b1 1e-12.\", \"state\": \"success\", \"details\": {\"parts\": []}, \"groups\": {\"test_group\": \"data_integrity\", \"test_type\": \"The Share of Missing Values in a Column\"}}, {\"title\": \"Share of Out-of-List Values\", \"description\": \"The share of values out of list in the column **Target** is 0 (0 out of 5315). The test threshold is eq=0 \\u00b1 1e-12.\", \"state\": \"success\", \"details\": {\"parts\": [{\"id\": \"eb05c175-ee8a-43fc-8800-14a5b253423a\", \"title\": \"Values inside the list (top 10)\", \"type\": \"widget\"}, {\"id\": \"cf994b26-0cb0-4dd0-a42f-a6858885efa9\", \"title\": \"Values outside the list (top 10)\", \"type\": \"widget\"}]}, \"groups\": {\"by_feature\": \"Target\", \"test_group\": \"data_quality\", \"test_type\": \"Share of Out-of-List Values\"}}], \"testGroupTypes\": [{\"id\": \"by_feature\", \"title\": \"By feature\", \"values\": [{\"id\": \"no group\", \"title\": \"Dataset-level tests\", \"description\": \"Some tests cannot be grouped by feature\", \"sort_index\": 0, \"severity\": null}]}, {\"id\": \"test_group\", \"title\": \"By test group\", \"values\": [{\"id\": \"no group\", \"title\": \"Ungrouped\", \"description\": \"Some tests don\\u2019t belong to any group under the selected condition\", \"sort_index\": 0, \"severity\": null}, {\"id\": \"classification\", \"title\": \"Classification\", \"description\": \"\", \"sort_index\": 0, \"severity\": null}, {\"id\": \"data_drift\", \"title\": \"Data Drift\", \"description\": \"\", \"sort_index\": 0, \"severity\": null}, {\"id\": \"data_integrity\", \"title\": \"Data Integrity\", \"description\": \"\", \"sort_index\": 0, \"severity\": null}, {\"id\": \"data_quality\", \"title\": \"Data Quality\", \"description\": \"\", \"sort_index\": 0, \"severity\": null}, {\"id\": \"regression\", \"title\": \"Regression\", \"description\": \"\", \"sort_index\": 0, \"severity\": null}]}, {\"id\": \"test_type\", \"title\": \"By test type\", \"values\": []}, {\"id\": \"by_class\", \"title\": \"By class\", \"values\": []}]}, \"insights\": [], \"alerts\": [], \"tabs\": [], \"widgets\": [], \"pageSize\": 5}]};\n",
              "    var additional_graphs_evidently_dashboard_f659b36f1e764defbd52061ceca44590 = {\"number_of_column\": {\"type\": \"table\", \"title\": \"\", \"size\": 2, \"id\": \"f7ae3564-3db5-4a89-b9f5-adc77e77c82c\", \"details\": \"\", \"alertsPosition\": null, \"alertStats\": null, \"params\": {\"header\": [\"column name\", \"current dtype\", \"reference dtype\"], \"data\": [[\"Target\", \"object\", \"object\"]]}, \"insights\": [], \"additionalGraphs\": [], \"alerts\": [], \"tabs\": [], \"widgets\": [], \"pageSize\": 5}, \"cd1c0672-63b1-4dd8-bfb2-8b1da08f8ac3\": {\"type\": \"table\", \"title\": \"\", \"size\": 2, \"id\": \"a43bfc2a-73ec-4af4-bc21-c4fab53e3313\", \"details\": \"\", \"alertsPosition\": null, \"alertStats\": null, \"params\": {\"header\": [\"Column Name\", \"Actual Type\", \"Expected Type\"], \"data\": [[\"Target\", \"object_\", \"object_\"]]}, \"insights\": [], \"additionalGraphs\": [], \"alerts\": [], \"tabs\": [], \"widgets\": [], \"pageSize\": 5}, \"eb05c175-ee8a-43fc-8800-14a5b253423a\": {\"type\": \"table\", \"title\": \"\", \"size\": 2, \"id\": \"4045bc31-beac-4320-a72e-70f84ffea4d1\", \"details\": \"\", \"alertsPosition\": null, \"alertStats\": null, \"params\": {\"header\": [\"value\", \"count\"], \"data\": [[\"javascript\", \"523\"], [\"html\", \"351\"], [\"c#\", \"336\"], [\"jquery\", \"290\"], [\"java\", \"207\"], [\"ios\", \"206\"], [\"php\", \"200\"], [\".net\", \"199\"], [\"css\", \"192\"], [\"sql\", \"161\"]]}, \"insights\": [], \"additionalGraphs\": [], \"alerts\": [], \"tabs\": [], \"widgets\": [], \"pageSize\": 5}, \"cf994b26-0cb0-4dd0-a42f-a6858885efa9\": {\"type\": \"table\", \"title\": \"\", \"size\": 2, \"id\": \"9280527a-210a-47a0-82d4-52640a9d83a7\", \"details\": \"\", \"alertsPosition\": null, \"alertStats\": null, \"params\": {\"header\": [\"value\", \"count\"], \"data\": []}, \"insights\": [], \"additionalGraphs\": [], \"alerts\": [], \"tabs\": [], \"widgets\": [], \"pageSize\": 5}};\n",
              "</script>\n",
              "<script>\n",
              "function domReady(fn) {\n",
              "  // If we're early to the party\n",
              "  document.addEventListener(\"DOMContentLoaded\", fn);\n",
              "  // If late; I mean on time.\n",
              "  if (document.readyState === \"interactive\" || document.readyState === \"complete\" ) {\n",
              "    fn();\n",
              "  }\n",
              "}\n",
              "\n",
              "domReady(function () {\n",
              "    requirejs([\"evidently\"], function(ev) {\n",
              "        drawDashboard(evidently_dashboard_f659b36f1e764defbd52061ceca44590,\n",
              "        new Map(Object.entries(additional_graphs_evidently_dashboard_f659b36f1e764defbd52061ceca44590)),\n",
              "        \"root_evidently_dashboard_f659b36f1e764defbd52061ceca44590\");\n",
              "    },\n",
              "    function(err) {\n",
              "        $(\"#root_evidently_dashboard_f659b36f1e764defbd52061ceca44590\").innerHTML = \"Failed to load\";\n",
              "    })\n",
              "});\n",
              "</script>\n",
              "<div class=\"reset-this-parent\" id=\"root_evidently_dashboard_f659b36f1e764defbd52061ceca44590\">Loading...</div>\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_stability.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\"/>\n",
              "<style>\n",
              ".reset-this-parent {\n",
              "  all: initial;\n",
              "}\n",
              ".reset-this-parent h5 {\n",
              "  all: initial;\n",
              "  font: initial;\n",
              "}\n",
              "\n",
              "svg {\n",
              "  height: intrinsic !important;\n",
              "}\n",
              "</style>\n",
              "<script>\n",
              "    var evidently_dashboard_345c5081f505420d9fdf05d16d251269 = {\"name\": \"Report\", \"widgets\": [{\"type\": \"counter\", \"title\": \"\", \"size\": 2, \"id\": \"23308240-806f-404e-b600-f722543c7c92\", \"details\": \"\", \"alertsPosition\": null, \"alertStats\": null, \"params\": {\"counters\": [{\"value\": \"Dataset Drift\", \"label\": \"Dataset Drift is detected. Dataset drift detection threshold is 0.5\"}]}, \"insights\": [], \"alerts\": [], \"tabs\": [], \"widgets\": [], \"pageSize\": 5}, {\"type\": \"counter\", \"title\": \"\", \"size\": 2, \"id\": \"aae2d70f-abed-4302-970f-8d3194222d34\", \"details\": \"\", \"alertsPosition\": null, \"alertStats\": null, \"params\": {\"counters\": [{\"value\": \"1\", \"label\": \"Columns\"}, {\"value\": \"1\", \"label\": \"Drifted Columns\"}, {\"value\": \"1.0\", \"label\": \"Share of Drifted Columns\"}]}, \"insights\": [], \"alerts\": [], \"tabs\": [], \"widgets\": [], \"pageSize\": 5}, {\"type\": \"counter\", \"title\": \"\", \"size\": 2, \"id\": \"acc51cf7-f751-4f7b-89d6-c248f5e3c743\", \"details\": \"\", \"alertsPosition\": null, \"alertStats\": null, \"params\": {\"counters\": [{\"value\": \"\", \"label\": \"Data Drift Summary\"}]}, \"insights\": [], \"alerts\": [], \"tabs\": [], \"widgets\": [], \"pageSize\": 5}, {\"type\": \"big_table\", \"title\": \"Drift is detected for 100.0% of columns (1 out of 1).\", \"size\": 2, \"id\": \"33b7c905-acaa-4383-8fa5-b7c59e64a8ed\", \"details\": \"\", \"alertsPosition\": \"row\", \"alertStats\": null, \"params\": {\"rowsPerPage\": 1, \"columns\": [{\"title\": \"Column\", \"field\": \"column_name\"}, {\"title\": \"Type\", \"field\": \"column_type\"}, {\"title\": \"Reference Distribution\", \"field\": \"reference_distribution\", \"type\": \"histogram\", \"options\": {\"xField\": \"x\", \"yField\": \"y\", \"color\": \"#ed0400\"}}, {\"title\": \"Current Distribution\", \"field\": \"current_distribution\", \"type\": \"histogram\", \"options\": {\"xField\": \"x\", \"yField\": \"y\", \"color\": \"#ed0400\"}}, {\"title\": \"Data Drift\", \"field\": \"data_drift\"}, {\"title\": \"Stat Test\", \"field\": \"stattest_name\"}, {\"title\": \"Drift Score\", \"field\": \"drift_score\"}], \"data\": [{\"details\": {\"parts\": [{\"title\": \"DATA DISTRIBUTION\", \"id\": \"1eb8be94-1798-445a-a391-cbfe8d620733\", \"type\": \"widget\"}]}, \"column_name\": \"Target\", \"column_type\": \"cat\", \"stattest_name\": \"Jensen-Shannon distance\", \"reference_distribution\": {\"x\": [\".net\", \"ajax\", \"android\", \"angular\", \"angularjs\", \"arrays\", \"asp.net\", \"asp.net-mvc\", \"c\", \"c#\", \"c++\", \"css\", \"database\", \"django\", \"forms\", \"html\", \"image\", \"ios\", \"iphone\", \"java\", \"javascript\", \"jquery\", \"json\", \"linux\", \"macos\", \"multithreading\", \"mysql\", \"node.js\", \"objective-c\", \"pandas\", \"performance\", \"php\", \"python\", \"python-3.x\", \"reactjs\", \"regex\", \"ruby\", \"ruby-on-rails\", \"spring\", \"spring-boot\", \"sql\", \"sql-server\", \"string\", \"swift\", \"visual-studio\", \"windows\", \"wordpress\", \"wpf\", \"xcode\", \"xml\"], \"y\": [41, 29, 25, 8, 12, 25, 29, 12, 14, 72, 18, 39, 20, 8, 13, 89, 8, 51, 26, 50, 121, 66, 21, 4, 6, 12, 37, 21, 38, 8, 14, 50, 40, 21, 9, 5, 7, 15, 17, 21, 29, 6, 23, 14, 9, 13, 10, 11, 17, 15]}, \"current_distribution\": {\"x\": [\".net\", \"ajax\", \"android\", \"angular\", \"angularjs\", \"arrays\", \"asp.net\", \"asp.net-mvc\", \"c\", \"c#\", \"c++\", \"css\", \"database\", \"django\", \"forms\", \"html\", \"image\", \"ios\", \"iphone\", \"java\", \"javascript\", \"jquery\", \"json\", \"linux\", \"macos\", \"multithreading\", \"mysql\", \"node.js\", \"objective-c\", \"pandas\", \"performance\", \"php\", \"python\", \"python-3.x\", \"reactjs\", \"regex\", \"ruby\", \"ruby-on-rails\", \"spring\", \"spring-boot\", \"sql\", \"sql-server\", \"string\", \"swift\", \"visual-studio\", \"windows\", \"wordpress\", \"wpf\", \"xcode\", \"xml\"], \"y\": [3, 0, 1, 0, 0, 1, 2, 1, 0, 6, 0, 1, 0, 0, 0, 6, 0, 4, 2, 1, 3, 6, 1, 2, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 1, 3, 2, 3, 2, 0, 0, 1, 1, 0]}, \"data_drift\": \"Detected\", \"drift_score\": 0.384368}]}, \"insights\": [], \"alerts\": [], \"tabs\": [], \"widgets\": [], \"pageSize\": 5}]};\n",
              "    var additional_graphs_evidently_dashboard_345c5081f505420d9fdf05d16d251269 = {\"1eb8be94-1798-445a-a391-cbfe8d620733\": {\"type\": \"big_graph\", \"title\": \"\", \"size\": 2, \"id\": \"1eb8be94-1798-445a-a391-cbfe8d620733\", \"details\": \"\", \"alertsPosition\": null, \"alertStats\": null, \"params\": {\"data\": [{\"marker\": {\"color\": \"#ed0400\"}, \"name\": \"current\", \"visible\": true, \"x\": [\"jquery\", \"c#\", \"html\", \"ios\", \".net\", \"sql-server\", \"javascript\", \"swift\", \"string\", \"regex\", \"asp.net\", \"iphone\", \"visual-studio\", \"linux\", \"xcode\", \"python\", \"mysql\", \"sql\", \"java\", \"multithreading\", \"arrays\", \"json\", \"css\", \"android\", \"asp.net-mvc\", \"php\", \"wpf\", \"objective-c\"], \"y\": [6, 6, 6, 4, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"type\": \"bar\", \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"#ed0400\"}, \"name\": \"current\", \"visible\": false, \"x\": [\"jquery\", \"c#\", \"html\", \"ios\", \".net\", \"sql-server\", \"javascript\", \"swift\", \"string\", \"regex\", \"asp.net\", \"iphone\", \"visual-studio\", \"linux\", \"xcode\", \"python\", \"mysql\", \"sql\", \"java\", \"multithreading\", \"arrays\", \"json\", \"css\", \"android\", \"asp.net-mvc\", \"php\", \"wpf\", \"objective-c\"], \"y\": [10.0, 10.0, 10.0, 6.666666666666667, 5.0, 5.0, 5.0, 5.0, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 3.3333333333333335, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667, 1.6666666666666667], \"type\": \"bar\", \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"#4d4d4d\"}, \"name\": \"reference\", \"visible\": true, \"x\": [\"javascript\", \"html\", \"c#\", \"jquery\", \"ios\", \"php\", \"java\", \".net\", \"python\", \"css\", \"objective-c\", \"mysql\", \"asp.net\", \"ajax\", \"sql\", \"iphone\", \"arrays\", \"android\", \"string\", \"spring-boot\", \"python-3.x\", \"json\", \"node.js\", \"database\", \"c++\", \"spring\", \"xcode\", \"xml\", \"ruby-on-rails\", \"swift\", \"performance\", \"c\", \"windows\", \"forms\", \"asp.net-mvc\", \"angularjs\", \"multithreading\", \"wpf\", \"wordpress\", \"visual-studio\", \"reactjs\", \"django\", \"angular\", \"image\", \"pandas\", \"ruby\", \"macos\", \"sql-server\", \"regex\", \"linux\"], \"y\": [121, 89, 72, 66, 51, 50, 50, 41, 40, 39, 38, 37, 29, 29, 29, 26, 25, 25, 23, 21, 21, 21, 21, 20, 18, 17, 17, 15, 15, 14, 14, 14, 13, 13, 12, 12, 12, 11, 10, 9, 9, 8, 8, 8, 8, 7, 6, 6, 5, 4], \"type\": \"bar\", \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"#4d4d4d\"}, \"name\": \"reference\", \"visible\": false, \"x\": [\"javascript\", \"html\", \"c#\", \"jquery\", \"ios\", \"php\", \"java\", \".net\", \"python\", \"css\", \"objective-c\", \"mysql\", \"asp.net\", \"ajax\", \"sql\", \"iphone\", \"arrays\", \"android\", \"string\", \"spring-boot\", \"python-3.x\", \"json\", \"node.js\", \"database\", \"c++\", \"spring\", \"xcode\", \"xml\", \"ruby-on-rails\", \"swift\", \"performance\", \"c\", \"windows\", \"forms\", \"asp.net-mvc\", \"angularjs\", \"multithreading\", \"wpf\", \"wordpress\", \"visual-studio\", \"reactjs\", \"django\", \"angular\", \"image\", \"pandas\", \"ruby\", \"macos\", \"sql-server\", \"regex\", \"linux\"], \"y\": [9.535066981875492, 7.0133963750985036, 5.673758865248227, 5.200945626477541, 4.0189125295508275, 3.940110323089047, 3.940110323089047, 3.230890464933018, 3.152088258471237, 3.0732860520094563, 2.9944838455476757, 2.9156816390858946, 2.2852639873916467, 2.2852639873916467, 2.2852639873916467, 2.048857368006304, 1.9700551615445234, 1.9700551615445234, 1.8124507486209613, 1.6548463356973995, 1.6548463356973995, 1.6548463356973995, 1.6548463356973995, 1.5760441292356184, 1.4184397163120568, 1.3396375098502757, 1.3396375098502757, 1.1820330969267139, 1.1820330969267139, 1.103230890464933, 1.103230890464933, 1.103230890464933, 1.024428684003152, 1.024428684003152, 0.9456264775413712, 0.9456264775413712, 0.9456264775413712, 0.8668242710795903, 0.7880220646178092, 0.7092198581560284, 0.7092198581560284, 0.6304176516942475, 0.6304176516942475, 0.6304176516942475, 0.6304176516942475, 0.5516154452324665, 0.4728132387706856, 0.4728132387706856, 0.3940110323089046, 0.31520882584712373], \"type\": \"bar\", \"xaxis\": \"x\", \"yaxis\": \"y\"}], \"layout\": {\"template\": {\"data\": {\"histogram2dcontour\": [{\"type\": \"histogram2dcontour\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}], \"choropleth\": [{\"type\": \"choropleth\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}], \"histogram2d\": [{\"type\": \"histogram2d\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}], \"heatmap\": [{\"type\": \"heatmap\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}], \"heatmapgl\": [{\"type\": \"heatmapgl\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}], \"contourcarpet\": [{\"type\": \"contourcarpet\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}], \"contour\": [{\"type\": \"contour\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}], \"surface\": [{\"type\": \"surface\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}], \"mesh3d\": [{\"type\": \"mesh3d\", \"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}], \"scatter\": [{\"fillpattern\": {\"fillmode\": \"overlay\", \"size\": 10, \"solidity\": 0.2}, \"type\": \"scatter\"}], \"parcoords\": [{\"type\": \"parcoords\", \"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"scatterpolargl\": [{\"type\": \"scatterpolargl\", \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}, \"pattern\": {\"fillmode\": \"overlay\", \"size\": 10, \"solidity\": 0.2}}, \"type\": \"bar\"}], \"scattergeo\": [{\"type\": \"scattergeo\", \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"scatterpolar\": [{\"type\": \"scatterpolar\", \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"histogram\": [{\"marker\": {\"pattern\": {\"fillmode\": \"overlay\", \"size\": 10, \"solidity\": 0.2}}, \"type\": \"histogram\"}], \"scattergl\": [{\"type\": \"scattergl\", \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"scatter3d\": [{\"type\": \"scatter3d\", \"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"scattermapbox\": [{\"type\": \"scattermapbox\", \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"scatterternary\": [{\"type\": \"scatterternary\", \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"scattercarpet\": [{\"type\": \"scattercarpet\", \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}, \"pattern\": {\"fillmode\": \"overlay\", \"size\": 10, \"solidity\": 0.2}}, \"type\": \"barpolar\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}]}, \"layout\": {\"autotypenumbers\": \"strict\", \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"hovermode\": \"closest\", \"hoverlabel\": {\"align\": \"left\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"bgcolor\": \"#E5ECF6\", \"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"ternary\": {\"bgcolor\": \"#E5ECF6\", \"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]]}, \"xaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"automargin\": true, \"zerolinewidth\": 2}, \"yaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"automargin\": true, \"zerolinewidth\": 2}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\", \"gridwidth\": 2}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\", \"gridwidth\": 2}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\", \"gridwidth\": 2}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"geo\": {\"bgcolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"subunitcolor\": \"white\", \"showland\": true, \"showlakes\": true, \"lakecolor\": \"white\"}, \"title\": {\"x\": 0.05}, \"mapbox\": {\"style\": \"light\"}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Count\"}}, \"updatemenus\": [{\"buttons\": [{\"args\": [{\"visible\": [true, false, true, false]}, {\"yaxis\": {\"title\": \"Count\"}}], \"label\": \"abs\", \"method\": \"update\"}, {\"args\": [{\"visible\": [false, true, false, true]}, {\"yaxis\": {\"title\": \"Percent\"}}], \"label\": \"perc\", \"method\": \"update\"}], \"direction\": \"right\", \"type\": \"buttons\", \"x\": 1.05, \"y\": 1.2, \"yanchor\": \"top\"}]}}, \"insights\": [], \"additionalGraphs\": [], \"alerts\": [], \"tabs\": [], \"widgets\": [], \"pageSize\": 5}};\n",
              "</script>\n",
              "<script>\n",
              "function domReady(fn) {\n",
              "  // If we're early to the party\n",
              "  document.addEventListener(\"DOMContentLoaded\", fn);\n",
              "  // If late; I mean on time.\n",
              "  if (document.readyState === \"interactive\" || document.readyState === \"complete\" ) {\n",
              "    fn();\n",
              "  }\n",
              "}\n",
              "\n",
              "domReady(function () {\n",
              "    requirejs([\"evidently\"], function(ev) {\n",
              "        drawDashboard(evidently_dashboard_345c5081f505420d9fdf05d16d251269,\n",
              "        new Map(Object.entries(additional_graphs_evidently_dashboard_345c5081f505420d9fdf05d16d251269)),\n",
              "        \"root_evidently_dashboard_345c5081f505420d9fdf05d16d251269\");\n",
              "    },\n",
              "    function(err) {\n",
              "        $(\"#root_evidently_dashboard_345c5081f505420d9fdf05d16d251269\").innerHTML = \"Failed to load\";\n",
              "    })\n",
              "});\n",
              "</script>\n",
              "<div class=\"reset-this-parent\" id=\"root_evidently_dashboard_345c5081f505420d9fdf05d16d251269\">Loading...</div>\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_drift_report.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rimnQGXIE1WJ",
        "outputId": "37e1c41e-25cc-429e-d315-28cb27ce696c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023/12/14 21:11:01 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'list' object has no attribute 'flatten'\n",
            "/Users/orphila_adjovi/PJT5_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/orphila_adjovi/PJT5_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
            "  warnings.warn(\n",
            "Registered model 'supervised_tfidf_vec' already exists. Creating a new version of this model...\n",
            "Created version '2' of model 'supervised_tfidf_vec'.\n",
            "2023/12/14 21:11:14 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La précision du modèle supervisé avec  Word2Vec  est de  10.0  % \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Registered model 'supervised' already exists. Creating a new version of this model...\n",
            "Created version '12' of model 'supervised'.\n"
          ]
        }
      ],
      "source": [
        "# @title Extraction de caractéristiques avec Word2Vec\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "\n",
        "sentences = [text.split() for text in df['Cleaned_Body']]\n",
        "\n",
        "# Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Dictionnaire de mots vers vecteurs\n",
        "word_vectors = word2vec_model.wv\n",
        "\n",
        "# Obtention du vecteur d'un document en moyennant les vecteurs de ses mots\n",
        "def document_vector(word_vectors, doc):\n",
        "    # Supprimer les mots absents du vocabulaire du modèle\n",
        "    doc = [word for word in doc if word in word_vectors.key_to_index]\n",
        "    if len(doc) > 0:\n",
        "        return np.mean(word_vectors[doc], axis=0)\n",
        "    else:\n",
        "        return np.zeros(word_vectors.vector_size)\n",
        "\n",
        "word2vec_features = np.array([document_vector(word_vectors, doc) for doc in sentences])\n",
        "\n",
        "word2vec_df = pd.DataFrame(word2vec_features, columns=[f'w2v_{i}' for i in range(word2vec_features.shape[1])])\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "word2vec_df = scaler.fit_transform(word2vec_df)\n",
        "modelisation(word2vec_df,'Word2Vec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UXUcx7vE1R1",
        "outputId": "d23f8de8-91eb-45cd-cac4-f1e01efaf0b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023/11/24 21:19:35 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
            "2023/11/24 21:20:30 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'list' object has no attribute 'flatten'\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La précision du modèle supervisé avec  USE  est de  12.0  % \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Registered model 'supervised' already exists. Creating a new version of this model...\n",
            "Created version '3' of model 'supervised'.\n"
          ]
        }
      ],
      "source": [
        "# @title Extraction de caractéristiques avec USE\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Modèle Universal Sentence Encoder\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "# Obtention du vecteur d'un document\n",
        "def get_use_embedding(text):\n",
        "    # Convertir le texte en embeddings\n",
        "    embeddings = embed([text])\n",
        "    return np.array(embeddings).flatten()\n",
        "\n",
        "\n",
        "use_features = np.array([get_use_embedding(text) for text in df['Cleaned_Body']])\n",
        "\n",
        "use_df = pd.DataFrame(use_features, columns=[f'use_{i}' for i in range(use_features.shape[1])])\n",
        "use_df = scaler.fit_transform(use_df)\n",
        "\n",
        "modelisation(word2vec_df,'USE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341,
          "referenced_widgets": [
            "bcc75a52ef1d4bbdbe532bfcc476e78b",
            "9f5139c304e041cebfd920b906ea4afd",
            "297ebabd74234d6dbeceb5fc5585af79",
            "06012e1d3c954a25a4a83a414f542d77",
            "4c3aedad854948b3b02a514848f11010",
            "ea26acf542444c0e9a035a65830baff6",
            "16d2fbea20fb4588b7d479add32c022a",
            "02b872fc1aaf486f8591e04ba78befa8",
            "7eb3c06be5f949f49fb718320353f801",
            "e9b234717d474fe4baa2009a5de8906b",
            "85499c4b38844d78baf30d9ffa696aa9",
            "40a6cb4faab54e049deea5e62195962d",
            "75b22e9628964513b7c9b09c41a1f929",
            "a6e0e177d52042f3b189ede67e8ecadf",
            "356c10ac8e9e4fc1a014c46d4c372520",
            "62772895db924dad986418f2b95dee51",
            "1dec784ca1d74ae6a2501622d55d1164",
            "3732c0404dbb488f96a2c87a5a8dc4c6",
            "e756bcdaf75542159fe36cb7f20e24ff",
            "f32dae0b9e294f63a0b041dc9e747cad",
            "86668b97620442aabe71f0a566cc3606",
            "55a6f08829704066bd693a0ddccce508",
            "a407a9edc20844cc918c66e808ee1874",
            "2561b5eeee104bd89cee2825b44f5314",
            "b3cf08ed3ef745299ff948bebbc04626",
            "8ddd57b4b05e4964ae1e08dd9023c481",
            "67d4ecee57b8427e8b110689e6bb6e01",
            "8e79923cbc36430aa60a23aacc658903",
            "18b1e1750ceb495abe5c8aea14fdf066",
            "733e11bb61464b45b684aab8daff2c19",
            "b466962ffad24169a6de5cdc1cee7352",
            "9822ce9ceeab4dd5bd39ac1af04a184f",
            "e00db7238ad64076919e86ce2d2e180b",
            "0a9cca4710f046adb252919439a53b8b",
            "ec9ea8717a77425faddb89d4602ab4b0",
            "e70c17b70c3e4996b22f587521b735a6",
            "1272034c179249baa8f75368a7e9801a",
            "78c81326bcb445d59e8c5faa238a328f",
            "3ef5c8ac59f94805a57102e7d2d619dd",
            "1a7523ec3ed443a1a99a35d4b9f7ed57",
            "980b2abc01954ae488e42411ad7bdede",
            "44ee1c10082747bd85bad4697eb0ca25",
            "e0ea300aa0f44235bd598507e67db7fd",
            "3565402a6d9b43baab983b0dc2e0a10b",
            "1ebfc48b23c9452ba3f064860b9d17a4",
            "13bb288ff5254b92a8c23d375dc75942",
            "ecc8354a24214df59884b4e0fdbc9e0e",
            "10d477dd2e2d47dd9f2c5f21e772b428",
            "83421811bded43248bfb113dc2fbe363",
            "07ce8cf9ca20485db5b76203f032df57",
            "3de94dcf95d1415083b79415d575817d",
            "5ed801cea1f84d55b0c4dde53d421730",
            "d60d99a5a42f4f47a3fe28ac3b53c6bc",
            "74d4f716b5154dd8acae1d968565ee33",
            "4ffd3ee953574ac09db2a6882218737b"
          ]
        },
        "id": "wXR6ESm7E8kT",
        "outputId": "0c5e5245-520e-4ee3-9aaa-8f56e1c6eaf3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023/11/24 21:20:59 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of transformers. If you encounter errors during autologging, try upgrading / downgrading transformers to a supported version, or try upgrading MLflow.\n",
            "2023/11/24 21:21:00 INFO mlflow.tracking.fluent: Autologging successfully enabled for transformers.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcc75a52ef1d4bbdbe532bfcc476e78b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40a6cb4faab54e049deea5e62195962d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a407a9edc20844cc918c66e808ee1874",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a9cca4710f046adb252919439a53b8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ebfc48b23c9452ba3f064860b9d17a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023/11/24 23:05:57 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'list' object has no attribute 'flatten'\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La précision du modèle supervisé avec  BERT  est de  13.0  % \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Registered model 'supervised' already exists. Creating a new version of this model...\n",
            "Created version '4' of model 'supervised'.\n"
          ]
        }
      ],
      "source": [
        "# @title Extraction de caractéristiques avec BERT\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Modèle BERT et le tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Obtention du vecteur d'un document\n",
        "def get_bert_embedding(text):\n",
        "    # Tokenizer le texte et obtenir les embeddings\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    outputs = model(**inputs)\n",
        "    # Prendre la sortie correspondant au [CLS] token\n",
        "    embeddings = outputs.last_hidden_state[:, 0, :].detach().numpy()\n",
        "    return np.array(embeddings).flatten()\n",
        "\n",
        "\n",
        "bert_features = np.array([get_bert_embedding(text) for text in df['Cleaned_Body']])\n",
        "\n",
        "bert_df = pd.DataFrame(bert_features, columns=[f'bert_{i}' for i in range(bert_features.shape[1])])\n",
        "bert_df = scaler.fit_transform(bert_df)\n",
        "\n",
        "modelisation(bert_df,'BERT')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02b872fc1aaf486f8591e04ba78befa8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06012e1d3c954a25a4a83a414f542d77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9b234717d474fe4baa2009a5de8906b",
            "placeholder": "​",
            "style": "IPY_MODEL_85499c4b38844d78baf30d9ffa696aa9",
            "value": " 28.0/28.0 [00:00&lt;00:00, 209B/s]"
          }
        },
        "07ce8cf9ca20485db5b76203f032df57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a9cca4710f046adb252919439a53b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec9ea8717a77425faddb89d4602ab4b0",
              "IPY_MODEL_e70c17b70c3e4996b22f587521b735a6",
              "IPY_MODEL_1272034c179249baa8f75368a7e9801a"
            ],
            "layout": "IPY_MODEL_78c81326bcb445d59e8c5faa238a328f"
          }
        },
        "10d477dd2e2d47dd9f2c5f21e772b428": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74d4f716b5154dd8acae1d968565ee33",
            "placeholder": "​",
            "style": "IPY_MODEL_4ffd3ee953574ac09db2a6882218737b",
            "value": " 440M/440M [00:05&lt;00:00, 93.5MB/s]"
          }
        },
        "1272034c179249baa8f75368a7e9801a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0ea300aa0f44235bd598507e67db7fd",
            "placeholder": "​",
            "style": "IPY_MODEL_3565402a6d9b43baab983b0dc2e0a10b",
            "value": " 570/570 [00:00&lt;00:00, 15.8kB/s]"
          }
        },
        "13bb288ff5254b92a8c23d375dc75942": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07ce8cf9ca20485db5b76203f032df57",
            "placeholder": "​",
            "style": "IPY_MODEL_3de94dcf95d1415083b79415d575817d",
            "value": "model.safetensors: 100%"
          }
        },
        "16d2fbea20fb4588b7d479add32c022a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18b1e1750ceb495abe5c8aea14fdf066": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a7523ec3ed443a1a99a35d4b9f7ed57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dec784ca1d74ae6a2501622d55d1164": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ebfc48b23c9452ba3f064860b9d17a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13bb288ff5254b92a8c23d375dc75942",
              "IPY_MODEL_ecc8354a24214df59884b4e0fdbc9e0e",
              "IPY_MODEL_10d477dd2e2d47dd9f2c5f21e772b428"
            ],
            "layout": "IPY_MODEL_83421811bded43248bfb113dc2fbe363"
          }
        },
        "2561b5eeee104bd89cee2825b44f5314": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e79923cbc36430aa60a23aacc658903",
            "placeholder": "​",
            "style": "IPY_MODEL_18b1e1750ceb495abe5c8aea14fdf066",
            "value": "tokenizer.json: 100%"
          }
        },
        "297ebabd74234d6dbeceb5fc5585af79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02b872fc1aaf486f8591e04ba78befa8",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7eb3c06be5f949f49fb718320353f801",
            "value": 28
          }
        },
        "3565402a6d9b43baab983b0dc2e0a10b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "356c10ac8e9e4fc1a014c46d4c372520": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86668b97620442aabe71f0a566cc3606",
            "placeholder": "​",
            "style": "IPY_MODEL_55a6f08829704066bd693a0ddccce508",
            "value": " 232k/232k [00:00&lt;00:00, 2.43MB/s]"
          }
        },
        "3732c0404dbb488f96a2c87a5a8dc4c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3de94dcf95d1415083b79415d575817d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ef5c8ac59f94805a57102e7d2d619dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40a6cb4faab54e049deea5e62195962d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75b22e9628964513b7c9b09c41a1f929",
              "IPY_MODEL_a6e0e177d52042f3b189ede67e8ecadf",
              "IPY_MODEL_356c10ac8e9e4fc1a014c46d4c372520"
            ],
            "layout": "IPY_MODEL_62772895db924dad986418f2b95dee51"
          }
        },
        "44ee1c10082747bd85bad4697eb0ca25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c3aedad854948b3b02a514848f11010": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ffd3ee953574ac09db2a6882218737b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55a6f08829704066bd693a0ddccce508": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ed801cea1f84d55b0c4dde53d421730": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62772895db924dad986418f2b95dee51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67d4ecee57b8427e8b110689e6bb6e01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "733e11bb61464b45b684aab8daff2c19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74d4f716b5154dd8acae1d968565ee33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75b22e9628964513b7c9b09c41a1f929": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dec784ca1d74ae6a2501622d55d1164",
            "placeholder": "​",
            "style": "IPY_MODEL_3732c0404dbb488f96a2c87a5a8dc4c6",
            "value": "vocab.txt: 100%"
          }
        },
        "78c81326bcb445d59e8c5faa238a328f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eb3c06be5f949f49fb718320353f801": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83421811bded43248bfb113dc2fbe363": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85499c4b38844d78baf30d9ffa696aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86668b97620442aabe71f0a566cc3606": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ddd57b4b05e4964ae1e08dd9023c481": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9822ce9ceeab4dd5bd39ac1af04a184f",
            "placeholder": "​",
            "style": "IPY_MODEL_e00db7238ad64076919e86ce2d2e180b",
            "value": " 466k/466k [00:00&lt;00:00, 9.34MB/s]"
          }
        },
        "8e79923cbc36430aa60a23aacc658903": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "980b2abc01954ae488e42411ad7bdede": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9822ce9ceeab4dd5bd39ac1af04a184f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f5139c304e041cebfd920b906ea4afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea26acf542444c0e9a035a65830baff6",
            "placeholder": "​",
            "style": "IPY_MODEL_16d2fbea20fb4588b7d479add32c022a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a407a9edc20844cc918c66e808ee1874": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2561b5eeee104bd89cee2825b44f5314",
              "IPY_MODEL_b3cf08ed3ef745299ff948bebbc04626",
              "IPY_MODEL_8ddd57b4b05e4964ae1e08dd9023c481"
            ],
            "layout": "IPY_MODEL_67d4ecee57b8427e8b110689e6bb6e01"
          }
        },
        "a6e0e177d52042f3b189ede67e8ecadf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e756bcdaf75542159fe36cb7f20e24ff",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f32dae0b9e294f63a0b041dc9e747cad",
            "value": 231508
          }
        },
        "b3cf08ed3ef745299ff948bebbc04626": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_733e11bb61464b45b684aab8daff2c19",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b466962ffad24169a6de5cdc1cee7352",
            "value": 466062
          }
        },
        "b466962ffad24169a6de5cdc1cee7352": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcc75a52ef1d4bbdbe532bfcc476e78b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f5139c304e041cebfd920b906ea4afd",
              "IPY_MODEL_297ebabd74234d6dbeceb5fc5585af79",
              "IPY_MODEL_06012e1d3c954a25a4a83a414f542d77"
            ],
            "layout": "IPY_MODEL_4c3aedad854948b3b02a514848f11010"
          }
        },
        "d60d99a5a42f4f47a3fe28ac3b53c6bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e00db7238ad64076919e86ce2d2e180b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0ea300aa0f44235bd598507e67db7fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e70c17b70c3e4996b22f587521b735a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_980b2abc01954ae488e42411ad7bdede",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44ee1c10082747bd85bad4697eb0ca25",
            "value": 570
          }
        },
        "e756bcdaf75542159fe36cb7f20e24ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9b234717d474fe4baa2009a5de8906b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea26acf542444c0e9a035a65830baff6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec9ea8717a77425faddb89d4602ab4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ef5c8ac59f94805a57102e7d2d619dd",
            "placeholder": "​",
            "style": "IPY_MODEL_1a7523ec3ed443a1a99a35d4b9f7ed57",
            "value": "config.json: 100%"
          }
        },
        "ecc8354a24214df59884b4e0fdbc9e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ed801cea1f84d55b0c4dde53d421730",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d60d99a5a42f4f47a3fe28ac3b53c6bc",
            "value": 440449768
          }
        },
        "f32dae0b9e294f63a0b041dc9e747cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
